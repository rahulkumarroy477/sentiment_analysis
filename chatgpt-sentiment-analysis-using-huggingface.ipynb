{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4992966,"sourceType":"datasetVersion","datasetId":2896084}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-09T06:41:56.005820Z","iopub.execute_input":"2024-10-09T06:41:56.006329Z","iopub.status.idle":"2024-10-09T06:41:57.057202Z","shell.execute_reply.started":"2024-10-09T06:41:56.006286Z","shell.execute_reply":"2024-10-09T06:41:57.056245Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/chatgpt-sentiment-analysis/file.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets transformers huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:41:57.058411Z","iopub.execute_input":"2024-10-09T06:41:57.058913Z","iopub.status.idle":"2024-10-09T06:42:21.529076Z","shell.execute_reply.started":"2024-10-09T06:41:57.058868Z","shell.execute_reply":"2024-10-09T06:42:21.527829Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nfrom bs4 import BeautifulSoup\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:42:21.531342Z","iopub.execute_input":"2024-10-09T06:42:21.532361Z","iopub.status.idle":"2024-10-09T06:42:23.241653Z","shell.execute_reply.started":"2024-10-09T06:42:21.532311Z","shell.execute_reply":"2024-10-09T06:42:23.240622Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\nsentiment_pipeline = pipeline(\"sentiment-analysis\")\ndata = [\"I like you\", \"I hate this movie\"]\nsentiment_pipeline(data)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:42:23.244075Z","iopub.execute_input":"2024-10-09T06:42:23.244544Z","iopub.status.idle":"2024-10-09T06:42:41.678830Z","shell.execute_reply.started":"2024-10-09T06:42:23.244510Z","shell.execute_reply":"2024-10-09T06:42:41.677841Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"320f5f3c8ebe46e9b38bfabec80cb77d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62540d75c3f54b4295ce50b724cea0e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4eef47630164a9d9cddc11bfbef59cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a334ca9e144c20aa7da490e29b09b1"}},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n {'label': 'NEGATIVE', 'score': 0.9996687173843384}]"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:42:41.680360Z","iopub.execute_input":"2024-10-09T06:42:41.681005Z","iopub.status.idle":"2024-10-09T06:42:41.689138Z","shell.execute_reply.started":"2024-10-09T06:42:41.680940Z","shell.execute_reply":"2024-10-09T06:42:41.687278Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/chatgpt-sentiment-analysis/file.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:42:41.690299Z","iopub.execute_input":"2024-10-09T06:42:41.690616Z","iopub.status.idle":"2024-10-09T06:42:42.915708Z","shell.execute_reply.started":"2024-10-09T06:42:41.690566Z","shell.execute_reply":"2024-10-09T06:42:42.914906Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:44.150621Z","iopub.execute_input":"2024-10-09T06:44:44.151039Z","iopub.status.idle":"2024-10-09T06:44:44.168646Z","shell.execute_reply.started":"2024-10-09T06:44:44.151003Z","shell.execute_reply":"2024-10-09T06:44:44.167803Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                             tweets   labels\n0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n1           1  Try talking with ChatGPT, our new AI system wh...     good\n2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n3           3  THRILLED to share that ChatGPT, our new model ...     good\n4           4  As of 2 minutes ago, @OpenAI released their ne...      bad","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:46.900584Z","iopub.execute_input":"2024-10-09T06:44:46.901716Z","iopub.status.idle":"2024-10-09T06:44:46.908586Z","shell.execute_reply.started":"2024-10-09T06:44:46.901661Z","shell.execute_reply":"2024-10-09T06:44:46.907602Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'tweets', 'labels'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(columns=['Unnamed: 0'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:49.424812Z","iopub.execute_input":"2024-10-09T06:44:49.425662Z","iopub.status.idle":"2024-10-09T06:44:49.440544Z","shell.execute_reply.started":"2024-10-09T06:44:49.425622Z","shell.execute_reply":"2024-10-09T06:44:49.439720Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:52.504843Z","iopub.execute_input":"2024-10-09T06:44:52.505747Z","iopub.status.idle":"2024-10-09T06:44:52.512099Z","shell.execute_reply.started":"2024-10-09T06:44:52.505705Z","shell.execute_reply":"2024-10-09T06:44:52.511006Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['tweets', 'labels'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:54.714980Z","iopub.execute_input":"2024-10-09T06:44:54.715582Z","iopub.status.idle":"2024-10-09T06:44:54.722216Z","shell.execute_reply.started":"2024-10-09T06:44:54.715542Z","shell.execute_reply":"2024-10-09T06:44:54.721244Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(219294, 2)"},"metadata":{}}]},{"cell_type":"code","source":"def remove_html_tags(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    return soup.get_text()\n\ndf['tweets'] = df['tweets'].apply(remove_html_tags)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:44:57.635281Z","iopub.execute_input":"2024-10-09T06:44:57.636016Z","iopub.status.idle":"2024-10-09T06:45:08.311656Z","shell.execute_reply.started":"2024-10-09T06:44:57.635972Z","shell.execute_reply":"2024-10-09T06:45:08.310676Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/4203560267.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, 'html.parser')\n/tmp/ipykernel_30/4203560267.py:2: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n  soup = BeautifulSoup(text, 'html.parser')\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              tweets   labels\n0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n1  Try talking with ChatGPT, our new AI system wh...     good\n2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n3  THRILLED to share that ChatGPT, our new model ...     good\n4  As of 2 minutes ago, @OpenAI released their ne...      bad","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntqdm.pandas()\n\n# Define punctuation and the function to remove punctuation\npunctuation = string.punctuation\n\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', punctuation))\n\n# Apply remove_punctuation function to 'tweets' column with tqdm progress\ndf['tweets'] = df['tweets'].progress_apply(remove_punctuation)\n\n# Lowercasing the text with tqdm progress\ndf['tweets'] = df['tweets'].progress_apply(lambda x: x.lower())\n\n# Display the modified DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:45:13.660385Z","iopub.execute_input":"2024-10-09T06:45:13.660770Z","iopub.status.idle":"2024-10-09T06:45:16.435616Z","shell.execute_reply.started":"2024-10-09T06:45:13.660732Z","shell.execute_reply":"2024-10-09T06:45:16.434416Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 219294/219294 [00:02<00:00, 98652.88it/s] \n100%|██████████| 219294/219294 [00:00<00:00, 435826.92it/s]\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                              tweets   labels\n0  chatgpt optimizing language models for dialogu...  neutral\n1  try talking with chatgpt our new ai system whi...     good\n2  chatgpt optimizing language models for dialogu...  neutral\n3  thrilled to share that chatgpt our new model o...     good\n4  as of 2 minutes ago openai released their new ...      bad","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>chatgpt optimizing language models for dialogu...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>try talking with chatgpt our new ai system whi...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>chatgpt optimizing language models for dialogu...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>thrilled to share that chatgpt our new model o...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>as of 2 minutes ago openai released their new ...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'] = df['labels'].map({'neutral': 0, 'good': 1, 'bad': 2})  # Convert sentiments to binary labels\ndf = df[['label', 'tweets']]","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:45:21.095238Z","iopub.execute_input":"2024-10-09T06:45:21.095625Z","iopub.status.idle":"2024-10-09T06:45:21.133649Z","shell.execute_reply.started":"2024-10-09T06:45:21.095582Z","shell.execute_reply":"2024-10-09T06:45:21.132817Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:45:25.064921Z","iopub.execute_input":"2024-10-09T06:45:25.065640Z","iopub.status.idle":"2024-10-09T06:45:25.777242Z","shell.execute_reply.started":"2024-10-09T06:45:25.065601Z","shell.execute_reply":"2024-10-09T06:45:25.776389Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset_split = dataset.train_test_split(test_size=0.3)\n\nsmall_train_dataset = dataset_split['train'].shuffle(seed=42).select([i for i in range(20000)])\n\nsmall_test_dataset = dataset_split['test'].shuffle(seed=42).select([i for i in range(5000)])","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:50:56.000793Z","iopub.execute_input":"2024-10-09T06:50:56.001954Z","iopub.status.idle":"2024-10-09T06:50:56.314537Z","shell.execute_reply.started":"2024-10-09T06:50:56.001897Z","shell.execute_reply":"2024-10-09T06:50:56.313761Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(\"\\nTraining dataset: \\n\")\nprint(small_train_dataset)\n\nprint(\"\\nTraining dataset: \\n\")\nprint(small_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:50:58.135037Z","iopub.execute_input":"2024-10-09T06:50:58.135730Z","iopub.status.idle":"2024-10-09T06:50:58.140802Z","shell.execute_reply.started":"2024-10-09T06:50:58.135690Z","shell.execute_reply":"2024-10-09T06:50:58.139849Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nTraining dataset: \n\nDataset({\n    features: ['label', 'tweets'],\n    num_rows: 20000\n})\n\nTraining dataset: \n\nDataset({\n    features: ['label', 'tweets'],\n    num_rows: 5000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:51:42.840549Z","iopub.execute_input":"2024-10-09T06:51:42.841293Z","iopub.status.idle":"2024-10-09T06:51:43.947471Z","shell.execute_reply.started":"2024-10-09T06:51:42.841252Z","shell.execute_reply":"2024-10-09T06:51:43.946485Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc6ee0da83fe47feae0f9c8809033808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a60554479743b4a30e7c51cfc3e094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1c104491b1b44c7a1eedca7f5e7a25c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"652a80ad94cd4cf0951c8f398405bdbe"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"tweets\"], truncation=True, padding=True)\n\ntokenized_train = small_train_dataset.map(preprocess_function, batched=True)\ntokenized_test = small_test_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:51:46.585152Z","iopub.execute_input":"2024-10-09T06:51:46.585869Z","iopub.status.idle":"2024-10-09T06:51:51.850249Z","shell.execute_reply.started":"2024-10-09T06:51:46.585827Z","shell.execute_reply":"2024-10-09T06:51:51.849385Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a36ce4b1f54f92a13935f628493fb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40cc96efa52b4310a2b299ac6b6ed416"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:51:54.090057Z","iopub.execute_input":"2024-10-09T06:51:54.090951Z","iopub.status.idle":"2024-10-09T06:51:54.095184Z","shell.execute_reply.started":"2024-10-09T06:51:54.090893Z","shell.execute_reply":"2024-10-09T06:51:54.094137Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:51:58.480924Z","iopub.execute_input":"2024-10-09T06:51:58.481853Z","iopub.status.idle":"2024-10-09T06:51:59.874156Z","shell.execute_reply.started":"2024-10-09T06:51:58.481812Z","shell.execute_reply":"2024-10-09T06:51:59.873151Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4c0a7ff2114f56adec4adfb93e099e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:03.440465Z","iopub.execute_input":"2024-10-09T06:52:03.441186Z","iopub.status.idle":"2024-10-09T06:52:15.729495Z","shell.execute_reply.started":"2024-10-09T06:52:03.441143Z","shell.execute_reply":"2024-10-09T06:52:15.728259Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport evaluate\n\n# Load accuracy and F1 metrics\naccuracy_metric = evaluate.load(\"accuracy\")\nf1_metric = evaluate.load(\"f1\")\n\n# Update compute_metrics function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n\n    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')  # Use 'weighted' for multi-class F1\n    return {\"accuracy\": accuracy, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:15.731493Z","iopub.execute_input":"2024-10-09T06:52:15.731846Z","iopub.status.idle":"2024-10-09T06:52:16.702861Z","shell.execute_reply.started":"2024-10-09T06:52:15.731807Z","shell.execute_reply":"2024-10-09T06:52:16.701970Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804f1b920c524bf38c0f839ca3ae5d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf3681d1fd954a50948101b5dc79daa7"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:19.589988Z","iopub.execute_input":"2024-10-09T06:52:19.590857Z","iopub.status.idle":"2024-10-09T06:52:19.617254Z","shell.execute_reply.started":"2024-10-09T06:52:19.590816Z","shell.execute_reply":"2024-10-09T06:52:19.616371Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40a5f7eb2af4516b9441df01ba15e8a"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments \n\nrepo_name = \"chatgpt-model-on-sentiment-analysis\"\n\ntraining_args = TrainingArguments(\n    output_dir=repo_name,\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    push_to_hub = True\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:39.996377Z","iopub.execute_input":"2024-10-09T06:52:39.996753Z","iopub.status.idle":"2024-10-09T06:52:40.075248Z","shell.execute_reply.started":"2024-10-09T06:52:39.996719Z","shell.execute_reply":"2024-10-09T06:52:40.074487Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:44.104635Z","iopub.execute_input":"2024-10-09T06:52:44.105325Z","iopub.status.idle":"2024-10-09T06:52:45.136299Z","shell.execute_reply.started":"2024-10-09T06:52:44.105282Z","shell.execute_reply":"2024-10-09T06:52:45.135516Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T06:52:48.136516Z","iopub.execute_input":"2024-10-09T06:52:48.137453Z","iopub.status.idle":"2024-10-09T07:07:29.782421Z","shell.execute_reply.started":"2024-10-09T06:52:48.137412Z","shell.execute_reply":"2024-10-09T07:07:29.781290Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113120099998418, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09aa19508b6e4dacb39a2cbf85585029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241009_065300-44lnw3ur</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface/runs/44lnw3ur' target=\"_blank\">chatgpt-model-on-sentiment-analysis</a></strong> to <a href='https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface' target=\"_blank\">https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface/runs/44lnw3ur' target=\"_blank\">https://wandb.ai/rahulkumarroy477-national-institute-of-technology-patna/huggingface/runs/44lnw3ur</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 14:24, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.747200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.522800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.429200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.370300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.352300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.255600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.252300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.222500</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.194800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.196000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.137600</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.153800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6250, training_loss=0.3129090856933594, metrics={'train_runtime': 880.5462, 'train_samples_per_second': 113.566, 'train_steps_per_second': 7.098, 'total_flos': 2493610781515776.0, 'train_loss': 0.3129090856933594, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:07:29.784576Z","iopub.execute_input":"2024-10-09T07:07:29.785001Z","iopub.status.idle":"2024-10-09T07:07:45.437516Z","shell.execute_reply.started":"2024-10-09T07:07:29.784955Z","shell.execute_reply":"2024-10-09T07:07:45.436595Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [313/313 00:15]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'f1': 0.8691176083746959}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5472574234008789,\n 'eval_accuracy': 0.8696,\n 'eval_f1': {'f1': 0.8691176083746959},\n 'eval_runtime': 15.6371,\n 'eval_samples_per_second': 319.752,\n 'eval_steps_per_second': 20.016,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:24:17.540497Z","iopub.execute_input":"2024-10-09T07:24:17.541332Z","iopub.status.idle":"2024-10-09T07:24:28.903806Z","shell.execute_reply.started":"2024-10-09T07:24:17.541291Z","shell.execute_reply":"2024-10-09T07:24:28.902896Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2ffa9108384f15bf74d7ad536b384a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1728457665.9a6430ad1243.30.1:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3f49d75ab04d448ffb30146a4f10da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63d6f3c8e1941028c3217bae5e0b723"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a91aec48ab4e24995971793c4a154c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1728456769.9a6430ad1243.30.0:   0%|          | 0.00/7.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d4877c967941e2abaec8ddfaad5401"}},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/rahulbaba/chatgpt-model-on-sentiment-analysis/commit/fee5a22689486119a026de0ff17e6aec814a4e8a', commit_message='End of training', commit_description='', oid='fee5a22689486119a026de0ff17e6aec814a4e8a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/rahulbaba/chatgpt-model-on-sentiment-analysis', endpoint='https://huggingface.co', repo_type='model', repo_id='rahulbaba/chatgpt-model-on-sentiment-analysis'), pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"# save_directory = \"/kaggle/working/sentiment_model_v1\"\n\n# trainer.save_model(save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:07:45.438649Z","iopub.execute_input":"2024-10-09T07:07:45.438967Z","iopub.status.idle":"2024-10-09T07:07:46.053669Z","shell.execute_reply.started":"2024-10-09T07:07:45.438909Z","shell.execute_reply":"2024-10-09T07:07:46.052644Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\nsentiment_model = pipeline(model=\"rahulbaba/chatgpt-model-on-sentiment-analysis\")\nsentiment_model([\"I like this move\", \"This movie is bad!\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:25:29.005958Z","iopub.execute_input":"2024-10-09T07:25:29.006692Z","iopub.status.idle":"2024-10-09T07:25:31.854820Z","shell.execute_reply.started":"2024-10-09T07:25:29.006650Z","shell.execute_reply":"2024-10-09T07:25:31.853810Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/769 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edd54bdd646b485ba88e64874c94d8f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9047cd1681a243dc805ef28726ccf04c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af73e84c58644267a99eb2b9ec69da25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d1028c574847729113ccd71918259d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5770cadd1542458e156f3a6058cd1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e273b7bb6f849caa260bdfb882c0e4f"}},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[{'label': 'LABEL_0', 'score': 0.9510214328765869},\n {'label': 'LABEL_2', 'score': 0.9976685643196106}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}